}
clean_text(test)
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
clean_text(test)
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
test_out
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
test_out
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
test_out
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
test_out
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text))
print(class(clean_df))
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text))
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
View(test_out)
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text))
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 100)
test_out <- process_pipeline(test_data)
test_out
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text)) %>%
mutate(str_count(text, "\\S+"))
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text)) %>%
mutate(word_count = str_count(text, "\\S+"))
}
hist(test_out$`str_count(text, "\\S+")`)
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
hist(test_out$`str_count(text, "\\S+")`)
hist(test_out$word_count)
hist(test_out$word_count, breaks = 10)
hist(test_out$word_count, breaks = 100)
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_words()
}
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_words()
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[1,2]
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out1 <- process_pipeline(test_data)
test_out1[1,2]
test_out[1,2]
test_out1[1,2]
lemmatize_strings("michael tompsett text map canvas art michael ireland text map product gallery this ready to gallery wrapped art piece features a map of ireland with cities and design were")
lemmatize_words("michael tompsett text map canvas art michael ireland text map product gallery this ready to gallery wrapped art piece features a map of ireland with cities and design were")
lemmatize_strings("michael tompsett text map canvas art michael ireland text map product gallery this ready to gallery wrapped art piece features a map of ireland with cities and design were")
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[40,2]
test_out1[40,2]
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[40,2]
test_out1[40,2]
test_out[40,2]
test_out1[40,2]
test_out[40,2]
test_out1[40,2]
disclaimer <- "While we aim to supply accurate product information it is sourced by manufacturers suppliers and marketplace sellers and has not been provided by Overstock"
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[40,2]
clean_text <- function(text) {
text %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
tolower %>%
lemmatize_strings
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[40,2]
clean_text <- function(text) {
text %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
test_data <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data)
test_out[40,2]
test_out[20,2]
test_out1[20,2]
test_data_raw <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data_raw)
test_out[20,2]
test_out1[20,2]
test_data_raw[20,]
test_data_raw[20,3]
test_out[20,2]
test_data_raw[20,3]
test_out[20,2]
test_data_raw[20,4]
test_data_raw[20,4][1]
test_data_raw$SHORT_DESCRIPTION[20]
test_data_raw$PRO_DESC[20]
disclaimer2 <- "While we aim to supply accurate product information, it is sourced by manufacturers, suppliers and marketplace sellers, and has not been provided by Overstock"
disclaimer <- "While we aim to supply accurate product information it is sourced by manufacturers suppliers and marketplace sellers and has not been provided by Overstock"
disclaimer2 <- "While we aim to supply accurate product information, it is sourced by manufacturers, suppliers and marketplace sellers, and has not been provided by Overstock"
clean_text <- function(text) {
text %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
gsub(disclaimer2, "", ., fixed = TRUE) %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
process_pipeline <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text)) %>%
mutate(word_count = str_count(text, "\\S+"))
}
clean_text <- function(text) {
text %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
gsub(disclaimer2, "", ., fixed = TRUE) %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings
}
test_data_raw <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 1000)
test_out <- process_pipeline(test_data_raw)
test_out[20,2]
test_out1[20,2]
test_out[40,2]
test_out1[40,2]
test_out[40,2]
test_out1[40,2]
hist(test_out$word_count, breaks = 100)
disclaimer1 <- "While we aim to supply accurate product information it is sourced by manufacturers suppliers and marketplace sellers and has not been provided by Overstock"
disclaimer2 <- "While we aim to supply accurate product information, it is sourced by manufacturers, suppliers and marketplace sellers, and has not been provided by Overstock"
test_out1[40,2]
test_out[41,2]
test_out1[41,2]
test_out[42,2]
test_out1[43,2]
test_out[43,2]
test_out1[43,2]
test_data_raw <- read_csv("../data/product_text/table_export_DATA.csv", n_max = 10000)
test_out <- process_pipeline(test_data_raw)
hist(test_out$word_count, breaks = 100)
hist(test_out$word_count, breaks = 100, xlim = 10)
hist(test_out$word_count, breaks = 100, xlim = c(10,100))
hist(test_out$word_count, breaks = 100, xlim = c(0,100))
file_pipe <- function(file) {
file %>%
read_csv %>%
process_pipe %>%
write_csv(file)
}
split_text_file("../data/test/test_chunk.csv")
split_text_file("../data/test/test_chunk.csv", line.count = 10)
file_pipe("../data/test/test_chunk copy.csv")
process_pipe <- function(product_text) {
clean_df <- product_text %>%
unite(., text, PRO_NAME:PRO_SHORT_NAME, sep = ". ", remove = TRUE) %>%
mutate(text = map_chr(text, clean_text)) %>%
mutate(word_count = str_count(text, "\\S+"))
}
clean_text <- function(text) {
text %>%
gsub(disclaimer, "", ., fixed = TRUE) %>%
gsub(disclaimer2, "", ., fixed = TRUE) %>%
str_extract_all("(?!(\\bin\\b)|(\\bx\\b)|(\\bft\\b)|[^A-Za-z0-9]\\w*|(\\w*[^A-Za-z0-9 \\n])|\\d|\\bNA\\b|(?<=[^a-zA-Z0-9 ])\\w*)\\b([a-zA-Z0-9])[a-zA-Z0-9]*\\b") %>%
unlist %>%
paste0(collapse = " ") %>%
tolower %>%
lemmatize_strings()
}
file_pipe <- function(file) {
file %>%
read_csv %>%
process_pipe %>%
write_csv(file)
}
file_pipe("../data/test/test_chunk copy.csv")
read_csv("../data/test/test_chunk/test_chunk00")
process_split_files <- function(fileid) {
files <- list.files(fileid)
pblapply(files, file_pipe)
}
detectCores() - 1
detectCores() - 1
process_split_files <- function(dir, cl = detectCores() - 1) {
files <- list.files(dir)
pblapply(files, file_pipe, cl = cl)
}
process_split_files <- function(dir, cl = detectCores() - 1) {
files <- list.files(dir)
pblapply(files, file_pipe, cl = cl)
}
process_split_files <- function(dir, cl = detectCores() - 1) {
files <- list.files(dir)
pblapply(files, file_pipe, cl = cl)
}
preprocess_data <- function(db_export_file) {
}
process_split_files <- function(dir, cl = detectCores() - 1) {
file_list <- list.files(dir)
file_list <- vapply(file_list, function(x) paste0(dir, x))
pblapply(file_list, file_pipe, cl = cl)
}
process_split_files("../data/test/test_chunk/")
process_split_files <- function(dir, cl = detectCores() - 1) {
file_list <- list.files(dir)
file_list <- vapply(file_list, function(x) paste0(dir, x), FUN.VALUE = "character")
pblapply(file_list, file_pipe, cl = cl)
}
process_split_files("../data/test/test_chunk/")
split_text_file("../data/test/test_chunk copy.csv")
split_text_file("../data/test/test_chunk.csv")
split_text_file("../data/test/test_chunk.csv", line.count = 10)
list.files("../data/test/test_chunk/")
file_dir <- paste0(filepath, fileid)
first_file <- list.files(file_dir)[[1]]
col_names <- colnames(read_csv(first_file))
file_dir <- paste0(filepath, fileid)
first_file <- list.files(file_dir)[[1]]
col_names <- colnames(read_csv(paste0(file_dir, first_file)))
file_dir <- paste0(filepath, fileid)
first_file <- list.files(file_dir)[[1]]
col_names <- colnames(read_csv(paste0(file_dir, "/", first_file)))
colnames()
colnames
col_names
paste0(col_names, collapse = ", ")
list.files(file_dir)[[1]]
list.files(file_dir)[[-1]]
file_list <- list.files(file_dir)
first_file <- file_list[[1]]
first_file
file_list[[1]] <- NULL
file_list[[1]]
file_list[1] <- NULL
file_list
file_list[[1]] <- NULL
file_list[-1]
in.file.path <- "../data/test/test_chunk.csv"
filepath <- str_extract(in.file.path, ".*\\/")
filename <- str_extract(in.file.path, "([^\\/]+)$")
fileid <- str_extract(in.file.path, "[ \\w-]+?(?=\\.)")
file_dir <- paste0(filepath, fileid)
file_list <- list.files(file_dir)
first_file <- file_list[[1]]
col_names <- paste0(colnames(read_csv(paste0(file_dir, "/", first_file))), collapse = ", ")
files_to_append <- file_list[-1]
col_names
col_names
seq_along(files_to_append)
files_to_append
file_dir
for(file in seq_along(files_to_append)) {
system(
paste0("sed  -i '1i ",  col_names, "' ", paste0(file_dir, "/", files_to_append[file])))
}
col_names
paste0(file_dir, "/", files_to_append[file])
paste0(file_dir, "/", files_to_append[file])
paste0(file_dir, "/", files_to_append[file])
paste0(file_dir, "/", files_to_append[file])
paste0(file_dir, "/", files_to_append[file])
paste0("sed  -i '1i ",  col_names, "' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file]))
for(file in seq_along(files_to_append)) {
system(
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file])))
}
split_text_file <- function(in.file.path, line.count = 10000, csv = TRUE) {
if(!file.exists(in.file.path)) {
stop(paste("File:", in.file.path, "could not be found"))
}
filepath <- str_extract(in.file.path, ".*\\/")
filename <- str_extract(in.file.path, "([^\\/]+)$")
fileid <- str_extract(in.file.path, "[ \\w-]+?(?=\\.)")
system(
paste(
paste("cd", filepath, "&& mkdir", fileid, "&& cd", fileid), "&&",
paste0("gsplit -l ", line.count, " --numeric-suffixes ", "../", filename, " ", fileid)))
if(csv == TRUE) {
file_dir <- paste0(filepath, fileid)
file_list <- list.files(file_dir)
first_file <- file_list[[1]]
col_names <- paste0(colnames(read_csv(paste0(file_dir, "/", first_file))), collapse = ", ")
files_to_append <- file_list[-1]
for(file in seq_along(files_to_append)) {
system(
paste0("sed  -i '' '1i\\\n",  col_names, "\n' ", paste0(file_dir, "/", files_to_append[file])))
}
}
}
split_text_file("../data/test/test_chunk.csv")
split_text_file("../data/test/test_chunk.csv", line.count = 10)
library(tidyverse)
library(stringr)
library(pbapply)
library(parallel)
library(textstem)
install.packages("textstem")
install.packages("textstem")
library(tidyverse)
library(stringr)
library(pbapply)
library(parallel)
library(textstem)
data_in <- read_csv("~/Desktop/test_out_full.csv")
View(data_in)
data_in <-
data_in %>%
filter(word_count > 50)
hist(data_in$word_count)
clean_corp1mil <- data_in %>% select(text)
View(clean_corp1mil)
write_delim(clean_corp1mil, path = "../data/product_text/corpus_clean_2.txt", delim = "\n", col_names = FALSE)
data_in <- read_csv("~/Desktop/test_out_full.csv")
library(tidyverse)
library(stringr)
library(pbapply)
library(parallel)
library(textstem)
data_in <- read_csv("~/Desktop/test_out_full.csv")
data_in <-
data_in %>%
filter(word_count > 50)
data_in <-
data_in %>%
filter(word_count > 60) %>%
select(text) %>%
sample_n(10000)
View(data_in)
write_delim(data_in, path = "../data/product_text/corpus_clean_2_10g_sample.txt", delim = "\n", col_names = FALSE)
